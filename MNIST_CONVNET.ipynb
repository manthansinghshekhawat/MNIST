{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNyZv-Ec52ot"
   },
   "source": [
    "# **Import Libraries and modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "3m3w1Cw49Zkt",
    "outputId": "dc02afeb-4426-4a24-dd1d-a9ff3a37c3f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "#We are first installing the keras package via pip install and importing the keras package\n",
    "# !pip install -q keras\n",
    "# import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Eso6UHE080D4"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f722dc5e632b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# importing np_utils from keras.utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# importing the mnist dataset from tensorflow.keras.datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfod1\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfod1\\lib\\site-packages\\keras\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfod1\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfod1\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_config'"
     ]
    }
   ],
   "source": [
    "# importing the numpy package with the alias np\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "# importing sequential model from keras.models\n",
    "from tensorflow.keras.models import Sequential\n",
    "# importing different layers and activations from keras.layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# importing np_utils from keras.utils\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# importing the mnist dataset from tensorflow.keras.datasets \n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zByEi95J86RD"
   },
   "source": [
    "### Load pre-shuffled MNIST data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7eRM0QWN83PV"
   },
   "outputs": [],
   "source": [
    "# we are downloading the MNIST dataset and splitting the data for training and testing\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "4a4Be72j8-ZC",
    "outputId": "2d052b70-b0c2-43d5-980b-e9f2b4a5dc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x216c1f219e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# printing out the shape of x_train\n",
    "print (X_train.shape)\n",
    "\n",
    "# importing pyplot with alias plt from matplotlib package\n",
    "from matplotlib import pyplot as plt\n",
    "# %matplotlib inline is a magic function to show us the plots in a notebook\n",
    "%matplotlib inline\n",
    "# plotting the first image or the image at index zero in the training dataset\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dkmprriw9AnZ"
   },
   "outputs": [],
   "source": [
    "#Reshaping our training and testing datatset using numpy's reshape function which we will feed to the model\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X2m4YS4E9CRh"
   },
   "outputs": [],
   "source": [
    "#Doing type conversion or changing the datatype to float32 for the data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#Doing standardization or normalization here dividind each pixel by 255 in the train and test data\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0Mn0vAYD9DvB",
    "outputId": "71607d41-7f17-40a8-a5c7-ebf40fc60ba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Checking first 10 image labels\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZG8JiXR39FHC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fe1adbab898e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert 1-dimensional class arrays to 10-dimensional class matrices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# simply we can say we are doing sort of onehot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "# simply we can say we are doing sort of onehot encoding\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "fYlFRvKS9HMB",
    "outputId": "f649ddd0-e414-4c56-83cc-32f25d576aa0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f02875c37326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# having a look in the first 10 datapoints after onehot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# having a look in the first 10 datapoints after onehot encoding\n",
    "Y_train[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "osKqT73Q9JJB",
    "outputId": "2bc5bcd3-f4c6-4db4-ab00-01704fddaf66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# importing Activation, BatchNormalization and MaxPooling2D from tensorflow.keras.layers for performing maxpooling and batchnormalizing operations and adding non linearity via activation functions\n",
    "from tensorflow.keras.layers import Activation,BatchNormalization\n",
    "# building our sequential model using the Sequential class and creating the model object\n",
    "model = Sequential()\n",
    "# Performing 2dconvolution followed by BatchNormalization and Dropout\n",
    "model.add(Conv2D(10, 3, 3, activation='relu', input_shape=(28,28,1))) # channel dimensions = 26x26x10    and Receptive field = 3x3\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Performing 2dconvolution followed by BatchNormalization and Dropout        \n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))                        # channel dimensions = 24x24x16    and Receptive field = 5x5\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Performing 2dconvolution followed Maxpoooling operation\n",
    "model.add(Conv2D(10, 1, 1, activation='relu')) #24                    # channel dimensions = 24x24x10    and Receptive field = 7x7 using 1x1 kernel\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))#12                                 # channel dimensions = 12x12x10    and Receptive field = 14x14\n",
    "\n",
    "# Performing 2dconvolution followed by BatchNormalization and Dropout\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))#10                     # channel dimensions = 10x10x16    and Receptive field = 16x16\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Performing 2dconvolution followed by BatchNormalization and Dropout\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))#8                      # channel dimensions = 8x8x16    and Receptive field = 18x18\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Performing 2dconvolution followed by BatchNormalization and Dropout\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))#6                      # channel dimensions = 6x6x16    and Receptive field = 20x20\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Performing 2dconvolution followed by BatchNormalization and Dropout\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))#4                      # channel dimensions = 4x4x16    and Receptive field = 22x22\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Performing only 2dconvolution at the last convolution layer(no batchnormalization and dropout)\n",
    "model.add(Conv2D(10, 4, 4))                                           # using 4x4 kernel to see the complete image\n",
    "\n",
    "# Here we are Flateening our dat i.e making it one dimensional which we will feed to the network.\n",
    "model.add(Flatten())\n",
    "#Using softmax activation function at the last layer which is used for multi class classification\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "id": "TzdAYg1k9K7Z",
    "outputId": "99bdf8a2-9eec-4c9c-c092-6630ab8fbea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 10)        170       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 16)        1456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 1, 10)          2570      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,072\n",
      "Trainable params: 12,892\n",
      "Non-trainable params: 180\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Seeing the summary of the complete model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1465
    },
    "id": "Zp6SuGrL9M3h",
    "outputId": "95cfa519-a393-497d-d4e5-71c3b7db2f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.2244 - acc: 0.9291 - val_loss: 0.0603 - val_acc: 0.9814\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0682 - acc: 0.9782 - val_loss: 0.0394 - val_acc: 0.9859\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0516 - acc: 0.9840 - val_loss: 0.0339 - val_acc: 0.9885\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0427 - acc: 0.9866 - val_loss: 0.0436 - val_acc: 0.9846\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0246 - val_acc: 0.9924\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0353 - acc: 0.9887 - val_loss: 0.0268 - val_acc: 0.9910\n",
      "Epoch 7/20\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0316 - acc: 0.9902 - val_loss: 0.0246 - val_acc: 0.9917\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0215 - val_acc: 0.9929\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0276 - acc: 0.9914 - val_loss: 0.0204 - val_acc: 0.9927\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.0259 - acc: 0.9918 - val_loss: 0.0211 - val_acc: 0.9929\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.0199 - val_acc: 0.9931\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0244 - acc: 0.9924 - val_loss: 0.0202 - val_acc: 0.9929\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0224 - acc: 0.9925 - val_loss: 0.0204 - val_acc: 0.9933\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0186 - val_acc: 0.9939\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0215 - acc: 0.9931 - val_loss: 0.0205 - val_acc: 0.9941\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.0187 - val_acc: 0.9936\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0179 - val_acc: 0.9947\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0188 - acc: 0.9939 - val_loss: 0.0176 - val_acc: 0.9949\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0184 - acc: 0.9939 - val_loss: 0.0178 - val_acc: 0.9947\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0185 - acc: 0.9937 - val_loss: 0.0168 - val_acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9b13cc5c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are importing the Adam Optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# We are importing the learningratescheduler callback\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "#Creating the \"scheduler\" function with two arguments i.e learningrate and epoch\n",
    "def scheduler(epoch, lr):\n",
    "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
    "\n",
    "#\tLearningRate = LearningRate * 1/(1 + decay * epoch) here decay is 0.319 and epoch is 10.\n",
    "\n",
    "# here we are compiling our model and using 'categorical_crossentropy' as our loss function and adam as our optimizer with learning rate =0.003 and metrics is accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
    "\n",
    "# Here we are traing our model using the data and using batch size of 128,number of epochs are 20 and using verbose=1 for printing out all the results.\n",
    "# In the callbacks parameter we are using the LearningRateScheduler which takes two arguments scheduler function which we built earlier to reduce the learning rate in each decay and verbose =1\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmx-CfrRiTPV"
   },
   "source": [
    "### Acheiving validation accuracy 99.40 in 16th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtsH-lLk-eLb"
   },
   "outputs": [],
   "source": [
    "# Here we are evaluating our model using the test data and saving the results in score variable\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mkX8JMv79q9r",
    "outputId": "09395f4e-1b4c-4829-d425-1abb5d70dafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.016840848704172823, 0.9948]\n"
     ]
    }
   ],
   "source": [
    "#printing the score or evaluation results\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCWoJkwE9suh"
   },
   "outputs": [],
   "source": [
    "#Finally we are doing the predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Ym7iCFBm9uBs",
    "outputId": "7c59eed8-03d1-43e8-c581-ba52ef391699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.18588875e-10 1.10197384e-07 9.42100868e-08 6.47855058e-09\n",
      "  1.69207333e-08 4.17292728e-10 3.07542240e-13 9.99999642e-01\n",
      "  9.12085338e-11 1.54161228e-07]\n",
      " [1.76716426e-07 1.01692115e-06 9.99997020e-01 2.61500765e-10\n",
      "  3.52892759e-09 6.02455724e-11 1.73723936e-06 4.81673978e-10\n",
      "  9.86598137e-10 7.51033957e-10]\n",
      " [4.95402723e-08 9.99971867e-01 1.43412436e-07 7.42149764e-09\n",
      "  4.27223176e-06 5.64623903e-08 6.43634053e-07 1.40830582e-06\n",
      "  2.14284719e-05 9.93460958e-08]\n",
      " [9.99749243e-01 2.12012385e-09 1.55717217e-07 1.60171410e-07\n",
      "  9.67361657e-08 6.64419986e-08 2.48599041e-04 4.07770955e-08\n",
      "  8.21720391e-07 7.01890883e-07]\n",
      " [1.39640198e-12 7.38510697e-10 9.39136546e-11 1.75288006e-09\n",
      "  9.99962568e-01 5.38754152e-10 1.31076794e-08 3.79924785e-08\n",
      "  3.76838614e-07 3.70355738e-05]\n",
      " [3.12427928e-09 9.99992728e-01 8.69713723e-09 2.73719630e-10\n",
      "  2.87195166e-06 1.32144284e-09 3.16081348e-08 3.78219397e-06\n",
      "  5.56979444e-07 5.58845734e-08]\n",
      " [8.57431259e-13 2.28732205e-07 1.04959685e-09 9.54893066e-13\n",
      "  9.99977469e-01 1.02809844e-10 1.84909184e-12 2.30325440e-06\n",
      "  8.50059223e-06 1.15253915e-05]\n",
      " [4.73914907e-09 4.90874697e-07 3.51914582e-06 7.28639350e-07\n",
      "  1.65146979e-04 3.59161731e-07 6.46610676e-09 6.53696816e-06\n",
      "  1.42087465e-05 9.99809086e-01]\n",
      " [3.23969268e-10 4.58688909e-09 1.15385774e-06 7.41597495e-09\n",
      "  1.17427040e-10 9.97740388e-01 1.99694466e-03 7.87983012e-11\n",
      "  2.58775864e-04 2.59662352e-06]]\n",
      "[7 2 1 0 4 1 4 9 5]\n"
     ]
    }
   ],
   "source": [
    "# Showing the results of predictions\n",
    "print(y_pred[:9])\n",
    "print(y_test[:9])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_CONVNET.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
